{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import VAE\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE    = 1\n",
    "EPOCHS        = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir             = os.getenv('DATA_DIR')\n",
    "SPECTROGRAMS_PATH    = os.path.join(data_dir, 'spectrograms')\n",
    "MODEL_DIR            = os.path.join(data_dir, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "os.environ[\"AWS_ACCESS_KEY_ID\"]      = os.getenv('S3_ACCESS_KEY')\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]  = os.getenv('S3_SECRET_KEY')\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = os.getenv('S3_URL')\n",
    "MLFLOW_URL                           = os.getenv('MLFLOW_URL')\n",
    "mlflow.set_tracking_uri(MLFLOW_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_fsdd(spectrograms_path):\n",
    "    x_train = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path) # (n_bins, n_frames, 1)\n",
    "            x_train.append(spectrogram)\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis] # -> (3000, 256, 64, 1)\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    with mlflow.start_run() as run:\n",
    "        x_train = load_fsdd(SPECTROGRAMS_PATH)\n",
    "\n",
    "        autoencoder = VAE(\n",
    "            input_shape=(256, 864, 1),\n",
    "            conv_filters=(512, 256, 128, 64, 32),\n",
    "            conv_kernels=(3, 3, 3, 3, 3),\n",
    "            conv_strides=(2, 2, 2, 2, (2, 1)),\n",
    "            latent_space_dim=128\n",
    "        )\n",
    "        autoencoder.summary()\n",
    "        autoencoder.compile(LEARNING_RATE)\n",
    "\n",
    "        mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        mlflow.log_param(\"epochs\", EPOCHS)\n",
    "\n",
    "        history = autoencoder.train(x_train, BATCH_SIZE, EPOCHS)\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            mlflow.log_metric(\"loss\", history.history['loss'][epoch], step=epoch)\n",
    "            mlflow.log_metric(\"_calculate_reconstruction_loss\", history.history['_calculate_reconstruction_loss'][epoch], step=epoch)\n",
    "            mlflow.log_metric(\"_calculate_kl_loss\", history.history['_calculate_kl_loss'][epoch], step=epoch)\n",
    "\n",
    "        autoencoder.save(MODEL_DIR)\n",
    "        \n",
    "        mlflow.log_artifact(MODEL_DIR)\n",
    "        #TODO mlflow.log_model\n",
    "\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
